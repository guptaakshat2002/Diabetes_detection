{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    # import the libraries
      import pandas as pd
      import numpy as np
      import matplotlib.pyplot as plt
      import seaborn as sns
      import warnings #avoid warning flash
       warnings.filterwarnings('ignore')

   ]
  },


# import dataset and read it
dataframe = pd.read_csv("diabetes.csv")
dataframe.head(15).style.set_properties(
    **{
         'background-color': 'Lightblue',
         'color': 'black',
         'border-color': 'white'
    })

print('Shape of Diabetes dataset is :',dataframe.shape)
print('Size of Diabetes dataset is  :',dataframe.size)

print(f'This Diabetes dataset has {dataframe.shape[0]} instances with the {dataframe.shape[1]-1} features and 1 output variable')

dataframe.columns

# Drop if there are duplicates rows.
dataframe = dataframe.drop_duplicates()

dataframe.info()

plt.rcParams.update({'font.size': 20})

dataframe.dtypes.value_counts().plot.pie(explode=[0.1, 0.1], autopct='%1.2f%%',shadow=True)                                      
plt.title('Data Type', color='Green', loc='center', font='Times New Roman');

dataframe.describe().style.set_properties(**{'background-color': 'Lightblue','color': 'black', 'border-color': 'white' })

plt.figure(figsize=(20,16))
corrmat=dataframe.corr()
sns.heatmap(corrmat, annot=True)

# show how many columns has 0 values and sum it
featureList = ['Glucose', 'BloodPressure','SkinThickness','Insulin','BMI']
print(dataframe[featureList].isin({0}).sum())

dataframe['Glucose']=dataframe['Glucose'].replace(0,dataframe['Glucose'].mean())#normal distribution
dataframe['BloodPressure']=dataframe['BloodPressure'].replace(0,dataframe['BloodPressure'].mean())#normal distribution
dataframe['SkinThickness']=dataframe['SkinThickness'].replace(0,dataframe['SkinThickness'].median())#skewed distribution
dataframe['Insulin']=dataframe['Insulin'].replace(0,dataframe['Insulin'].median())#skewed distribution
dataframe['BMI']=dataframe['BMI'].replace(0,dataframe['BMI'].median())#skewed distribution

featureList = ['Glucose', 'BloodPressure','SkinThickness','Insulin','BMI']
print(dataframe[featureList].isin({0}).sum())

# !pip install missingno

# check for Null values 
import missingno as msno
msno.bar(dataframe)
plt.show()

# replacing the value 0 and 1 in column name Outcome for readability
dataframe["Outcome"].replace(0,"Non-Diabetic",inplace=True) 
dataframe["Outcome"].replace(1,"Diabetic",inplace=True)
dataframe["Outcome"]

# plot the no of patients 
plt.figure(figsize=(14,6))

ax = plt.subplot(1,2,1)
ax = sns.countplot(x='Outcome', data=dataframe)
# ax.bar_label(ax.containers[0])
plt.title("Outcome", fontsize=20)

ax =plt.subplot(1,2,2)
ax=dataframe['Outcome'].value_counts().plot.pie(explode=[0.1, 0.1],autopct='%1.2f%%',shadow=True);
ax.set_title(label = "Outcome", fontsize = 20,color='Red',font='Lucida Calligraphy');

# for my analysis purpose i am saving the diabetic and non-diabetic data in different variables.
Diabetic = dataframe[dataframe["Outcome"]=="Diabetic"]
Non_diabetic = dataframe[dataframe["Outcome"]=="Non-Diabetic"]

Diabetic.describe()

Non_diabetic.describe()

x1=len(dataframe[dataframe["Glucose"]<=140])
x2=len(dataframe[(dataframe["Glucose"]>140)&(dataframe["Glucose"]<=199)])
x3=len(dataframe[dataframe["Glucose"]>=200])
print("patient count having normal Blood sugar :",x1)
print("patient count having prediabetes :",x2)
print("patient count having abnormal glucose :",x3)

sns.displot(dataframe, x='BMI', hue='Outcome', kind='kde')

### saving the patient details whose Glucose level is normal and are diabetic in a dataframe.
a=dataframe[(dataframe["Glucose"]<=140)&(dataframe["Outcome"]=="Diabetic")]

import seaborn as sns
sns.catplot(x="Outcome",y="Glucose",data=a)

sns.catplot(x="Outcome",y="BloodPressure",data=a, kind="swarm")

sns.catplot(x="Outcome",y="BMI",data=a, kind="swarm")

z=dataframe[(dataframe["Age"]>=35) & (dataframe["BMI"]>=30)& (dataframe["Outcome"]=="Diabetic")]
z[z["Pregnancies"]==0]

plt.figure(figsize=(24,16))
sns.relplot(x='Glucose',y="Insulin",data=dataframe,hue="Outcome")

# Age vs BMI
sns.relplot(x='Age',y="BMI",data=dataframe,hue="Outcome")

# BMI VS SKINTHICKNESS
sns.relplot(x='BMI',y="SkinThickness",data=dataframe,hue="Outcome")

dataframe.hist(figsize = (20,20))

# Using for loop to visualize the boxplot to detect outliers
x = dataframe.drop(['Outcome'],axis = 1) # drop dependent feature and plot the outliers.
for i in x.columns:
    sns.boxplot(x = i, data = x,color = 'blue')
    plt.xlabel(i)
    plt.show()

sns.pairplot(dataframe,vars=['Pregnancies','BloodPressure','SkinThickness','BMI','Glucose','Insulin','Age'],hue='Outcome',palette='plasma',aspect=1.9)

# Feature Selection
df_selected=dataframe.copy(deep=True)

# Quantile Transformer 
from sklearn.preprocessing import QuantileTransformer
x=df_selected
quantile  = QuantileTransformer()
X = quantile.fit_transform(x)
df_new=quantile.transform(X)
df_new=pd.DataFrame(X)
df_new.columns =['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction','Age', 'Outcome']
df_new.head()

# verify if the outliers are present or not.
x = df_new.drop(['Outcome'],axis = 1)
for i in x.columns:
    sns.boxplot(x = i, data = x,color = 'blue') 
    plt.xlabel(i)
    plt.show()

X = df_new.drop(columns='Outcome', axis=1)
Y = df_new['Outcome']

X.head() # independent features

Y.tail()  # Dependent features

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test= train_test_split(X,Y,test_size=0.2,random_state=12) 

X_train.shape, y_train.shape

X_test.shape, y_test.shape

!pip install --upgrade scikit-learn

from sklearn.metrics import accuracy_score,classification_report,confusion_matrix
from sklearn.linear_model import LogisticRegression
logic = LogisticRegression()
logic.fit(X_train, y_train)
y_pred_lr = logic.predict(X_test)

log_train = round(logic.score(X_train, y_train) * 100, 2)
log_accuracy = round(accuracy_score(y_pred_lr, y_test) * 100, 2)

print("Training Accuracy    :",log_train ,"%")
print("Model Accuracy Score :",log_accuracy ,"%")
print("\033[1m--------------------------------------------------------\033[0m")
print("Classification_Report: \n",classification_report(y_test,y_pred_lr))
print("\033[1m--------------------------------------------------------\033[0m")

from sklearn.svm import SVC
svc = SVC()
svc.fit(X_train, y_train)
y_pred_svc = svc.predict(X_test)

svc_train = round(svc.score(X_train, y_train) * 100, 2)
svc_accuracy = round(accuracy_score(y_pred_svc, y_test) * 100, 2)

print("Training Accuracy    :",svc_train ,"%")
print("Model Accuracy Score :",svc_accuracy ,"%")
print("\033[1m--------------------------------------------------------\033[0m")
print("Classification_Report: \n",classification_report(y_test,y_pred_svc))
print("\033[1m--------------------------------------------------------\033[0m")

from sklearn.tree import DecisionTreeClassifier
decision = DecisionTreeClassifier()
decision.fit(X_train, y_train)
y_pred_dec = decision.predict(X_test)

decision_train = round(decision.score(X_train, y_train) * 100, 2)
decision_accuracy = round(accuracy_score(y_pred_dec, y_test) * 100, 2)

print("Training Accuracy    :",decision_train ,"%")
print("Model Accuracy Score :",decision_accuracy ,"%")
print("\033[1m--------------------------------------------------------\033[0m")
print("Classification_Report: \n",classification_report(y_test,y_pred_dec))
print("\033[1m--------------------------------------------------------\033[0m")

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors = 3)
knn.fit(X_train, y_train)
y_pred_knn = knn.predict(X_test)

knn_train = round(knn.score(X_train, y_train) * 100, 2)
knn_accuracy = round(accuracy_score(y_pred_knn, y_test) * 100, 2)

print("Training Accuracy    :",knn_train ,"%")
print("Model Accuracy Score :",knn_accuracy ,"%")
print("\033[1m--------------------------------------------------------\033[0m")
print("Classification_Report: \n",classification_report(y_test,y_pred_knn))
print("\033[1m--------------------------------------------------------\033[0m")

# Create a variable 
models = pd.DataFrame({'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression','Decission Tree'],
                       'Training Accuracy':[svc_train,knn_train,log_train,decision_train],
                       'Model Accuracy':[svc_accuracy,knn_accuracy,log_accuracy,decision_accuracy]})

models.sort_values(by='Model Accuracy', ascending=False).style.background_gradient(
        cmap='coolwarm').hide_index().set_properties(**{
            'font-family': 'Lucida Calligraphy',
            'color': 'LigntGreen',
            'font-size': '15px'
        })

colors = ["blue", "blue", "blue", "blue","blue","blue"]

sns.set_style("whitegrid")
plt.figure(figsize=(16,8))
plt.ylabel("Accuracy %")
plt.xlabel("Algorithms")
sns.barplot(x=models['Model'],y=models['Model Accuracy'], palette=colors )
plt.show()

